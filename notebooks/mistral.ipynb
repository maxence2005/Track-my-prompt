{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://console.mistral.ai/api-keys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list', 'data': [{'id': 'ministral-3b-2410', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'ministral-3b-2410', 'description': 'Official ministral-3b-2410 Mistral AI model', 'max_context_length': 32768, 'aliases': ['ministral-3b-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'ministral-3b-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'ministral-3b-2410', 'description': 'Official ministral-3b-2410 Mistral AI model', 'max_context_length': 32768, 'aliases': ['ministral-3b-2410'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'ministral-8b-2410', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'ministral-8b-2410', 'description': 'Official ministral-8b-2410 Mistral AI model', 'max_context_length': 32768, 'aliases': ['ministral-8b-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'ministral-8b-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'ministral-8b-2410', 'description': 'Official ministral-8b-2410 Mistral AI model', 'max_context_length': 32768, 'aliases': ['ministral-8b-2410'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'open-mistral-7b', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-7b', 'description': 'Official open-mistral-7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-tiny', 'mistral-tiny-2312'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-tiny', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-7b', 'description': 'Official open-mistral-7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['open-mistral-7b', 'mistral-tiny-2312'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-tiny-2312', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-7b', 'description': 'Official open-mistral-7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['open-mistral-7b', 'mistral-tiny'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'open-mistral-nemo', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-nemo', 'description': 'Official open-mistral-nemo Mistral AI model', 'max_context_length': 131072, 'aliases': ['open-mistral-nemo-2407', 'mistral-tiny-2407', 'mistral-tiny-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'open-mistral-nemo-2407', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-nemo', 'description': 'Official open-mistral-nemo Mistral AI model', 'max_context_length': 131072, 'aliases': ['open-mistral-nemo', 'mistral-tiny-2407', 'mistral-tiny-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'mistral-tiny-2407', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-nemo', 'description': 'Official open-mistral-nemo Mistral AI model', 'max_context_length': 131072, 'aliases': ['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'mistral-tiny-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mistral-nemo', 'description': 'Official open-mistral-nemo Mistral AI model', 'max_context_length': 131072, 'aliases': ['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-2407'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'open-mixtral-8x7b', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mixtral-8x7b', 'description': 'Official open-mixtral-8x7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-small', 'mistral-small-2312'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-small', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mixtral-8x7b', 'description': 'Official open-mixtral-8x7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['open-mixtral-8x7b', 'mistral-small-2312'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-small-2312', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mixtral-8x7b', 'description': 'Official open-mixtral-8x7b Mistral AI model', 'max_context_length': 32768, 'aliases': ['open-mixtral-8x7b', 'mistral-small'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'open-mixtral-8x22b', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mixtral-8x22b', 'description': 'Official open-mixtral-8x22b Mistral AI model', 'max_context_length': 65536, 'aliases': ['open-mixtral-8x22b-2404'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'open-mixtral-8x22b-2404', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'open-mixtral-8x22b', 'description': 'Official open-mixtral-8x22b Mistral AI model', 'max_context_length': 65536, 'aliases': ['open-mixtral-8x22b'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-small-2402', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-small-2402', 'description': 'Official mistral-small-2402 Mistral AI model', 'max_context_length': 32768, 'aliases': [], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'mistral-small-2409', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-small-2409', 'description': 'Official mistral-small-2409 Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-small-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-small-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-small-2409', 'description': 'Official mistral-small-2409 Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-small-2409'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-medium-2312', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-medium-2312', 'description': 'Official mistral-medium-2312 Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-medium', 'mistral-medium-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-medium', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-medium-2312', 'description': 'Official mistral-medium-2312 Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-medium-2312', 'mistral-medium-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-medium-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-medium-2312', 'description': 'Official mistral-medium-2312 Mistral AI model', 'max_context_length': 32768, 'aliases': ['mistral-medium-2312', 'mistral-medium'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-large-2402', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-large-2402', 'description': 'Official mistral-large-2402 Mistral AI model', 'max_context_length': 32768, 'aliases': [], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'mistral-large-2407', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-large-2407', 'description': 'Official mistral-large-2407 Mistral AI model', 'max_context_length': 131072, 'aliases': ['mistral-large-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'mistral-large-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-large-2407', 'description': 'Official mistral-large-2407 Mistral AI model', 'max_context_length': 131072, 'aliases': ['mistral-large-2407'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'codestral-2405', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'codestral-2405', 'description': 'Official codestral-2405 Mistral AI model', 'max_context_length': 32768, 'aliases': ['codestral-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': True, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'codestral-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'codestral-2405', 'description': 'Official codestral-2405 Mistral AI model', 'max_context_length': 32768, 'aliases': ['codestral-2405'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': True, 'function_calling': True, 'fine_tuning': True, 'vision': False}, 'type': 'base'}, {'id': 'codestral-mamba-2407', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'codestral-mamba-2407', 'description': 'Official codestral-mamba-2407 Mistral AI model', 'max_context_length': 32768, 'aliases': ['open-codestral-mamba', 'codestral-mamba-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'open-codestral-mamba', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'codestral-mamba-2407', 'description': 'Official codestral-mamba-2407 Mistral AI model', 'max_context_length': 32768, 'aliases': ['codestral-mamba-2407', 'codestral-mamba-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'codestral-mamba-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'codestral-mamba-2407', 'description': 'Official codestral-mamba-2407 Mistral AI model', 'max_context_length': 32768, 'aliases': ['codestral-mamba-2407', 'open-codestral-mamba'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}, {'id': 'pixtral-12b-2409', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'pixtral-12b-2409', 'description': 'Official pixtral-12b-2409 Mistral AI model', 'max_context_length': 131072, 'aliases': ['pixtral-12b', 'pixtral-12b-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': True}, 'type': 'base'}, {'id': 'pixtral-12b', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'pixtral-12b-2409', 'description': 'Official pixtral-12b-2409 Mistral AI model', 'max_context_length': 131072, 'aliases': ['pixtral-12b-2409', 'pixtral-12b-latest'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': True}, 'type': 'base'}, {'id': 'pixtral-12b-latest', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'pixtral-12b-2409', 'description': 'Official pixtral-12b-2409 Mistral AI model', 'max_context_length': 131072, 'aliases': ['pixtral-12b-2409', 'pixtral-12b'], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': True}, 'type': 'base'}, {'id': 'mistral-embed', 'object': 'model', 'created': 1731433102, 'owned_by': 'mistralai', 'name': 'mistral-embed', 'description': 'Official mistral-embed Mistral AI model', 'max_context_length': 32768, 'aliases': [], 'deprecation': None, 'capabilities': {'completion_chat': True, 'completion_fim': False, 'function_calling': True, 'fine_tuning': False, 'vision': False}, 'type': 'base'}]}\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    url = \"https://api.mistral.ai/v1/models\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # On extrait le JSON\n",
    "            result = response.json()\n",
    "            return result\n",
    "        except ValueError:\n",
    "            print(\"Erreur lors de la conversion de la réponse en JSON\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Erreur API: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "print(get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"cat\", \"person\"]\n"
     ]
    }
   ],
   "source": [
    "# Configuration de l'API Mistral\n",
    "MISTRAL_API_URL = \"https://api.mistral.ai/v1/chat/completions\"  # Endpoint correct\n",
    "\n",
    "# Fonction pour appeler l'API Mistral\n",
    "def generate_json_from_prompt(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    # Construction du payload avec le prompt et la liste d'éléments\n",
    "    payload = {\n",
    "        \"model\": \"mistral-large-2407\",  # Modèle par défaut\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        \"max_tokens\": 200,  # Limite de tokens pour la réponse\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    # Appel de l'API\n",
    "    response = requests.post(MISTRAL_API_URL, json=payload, headers=headers)\n",
    "    \n",
    "    # Gestion de la réponse\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # On extrait le JSON\n",
    "            result = response.json()\n",
    "            # Filtrage pour obtenir uniquement la liste d'éléments recherchés\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except ValueError:\n",
    "            print(\"Erreur lors de la conversion de la réponse en JSON\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Erreur API: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "prompt = \"\"\"You are an AI that aims to be integrated into an application called Track-My-Prompt, which is an application that aims to find certain content in an image. This application has a prompt field, where you will be used. In this field we want to detect what the user is looking for. We have the ability to detect objects only from this list, which we will call the list of detectables: ['person', 'backpack', 'umbrella', 'handbag', 'suitcase', 'tie', 'bicycle', 'car', 'motorcycle', 'airplane', 'train', 'bus', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'sheep', 'cow', 'cat', 'horse', 'dog', 'bird', 'elephant', 'bear', 'baseball glove', 'kite', 'giraffe', 'zebra', 'tennis racket', 'skateboard', 'sports ball', 'baseball bat', 'snowboard', 'frisbee', 'skis', 'bottle', 'wine glass', 'fork', 'cup', 'knife', 'spoon', 'bowl', 'cake', 'donut', 'hot dog', 'pizza', 'carrot', 'broccoli', 'sandwich', 'orange', 'apple', 'banana', 'couch', 'chair', 'potted plant', 'bed', 'toilet', 'dining table', 'keyboard', 'cell phone', 'remote', 'laptop', 'tv', 'mouse', 'microwave', 'oven', 'sink', 'toaster', 'refrigerator', 'teddy bear', 'hair drier', 'toothbrush', 'scissors', 'clock', 'book', 'vase']\n",
    "Via the user prompt that will follow, which can be in any language, you must be able to send me back as output a list of this form: [\"requested object 1\", \"requested object 2\" ...], the elements of this list must be in the same order as the elements of the list above, if an element is not present in the user prompt, do not include it in the output. for example, user inputs \"dog\" and \"vacuum cleaner\". the vacuum cleaner is not in the list therefore you should not include it. If an element is present several times, for example \"dog\", \"dog\", in the user prompt, do not repeat it. Please verify all elements in output list are in the detectable list.\n",
    "I want only this list as output, no superfluous text, it is intended to be used by a computer that understands nothing other than precise instructions, this list is a precise instruction.\n",
    "Here is the user prompt, don't forget to translate it in english before : \"\"\"\n",
    "\n",
    "user = \"Uniquement des chats, pas des chiens, aussi je veux detecter des femmes\"\n",
    "\n",
    "prompt += user\n",
    "result = generate_json_from_prompt(prompt)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
